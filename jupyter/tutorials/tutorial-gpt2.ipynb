{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6aa8dce-6443-492f-8590-c53532856cb3",
   "metadata": {},
   "source": [
    "# Deploying GPT-2 to ODSP\n",
    "\n",
    "This notebook will showcase an example of how to deploy a language transformer model from Huggingface on the Open Data Science Platform.\n",
    "\n",
    "In this notebook, we will show how to access GPT-2 via Hugging Face, create a pipeline for the model, and register the model using `MLFlow`, and use that model as it is automatically deployed to the platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cae3b71-6194-4b1a-8f36-1aaed34f82ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import all required packages\n",
    "from transformers import pipeline\n",
    "import requests\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf7d12a-9ec3-429e-82d2-638eba01a489",
   "metadata": {},
   "source": [
    "## Access GPT-2 and Create a Transformers Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3a1815-cc67-4f9c-89e8-b5fca2e66811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a text generation transformers pipeline object for GPT-2\n",
    "model_id = 'gpt2'\n",
    "model = pipeline('text-generation', model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bcc259-0a9d-438b-bd32-c1fe3e28c6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model signature & config \n",
    "data = ['How are you today?']\n",
    "signature_output = mlflow.transformers.generate_signature_output(model, data)\n",
    "signature = mlflow.models.infer_signature(data, signature_output)\n",
    "model_config = {\n",
    "    'max_new_tokens' : 50,\n",
    "    'do_sample' : False,\n",
    "    'return_full_text' : False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cac9531-c77b-4a6b-b99e-567b0ea899d3",
   "metadata": {},
   "source": [
    "## Log and Register GPT-2 Model Pipeline with MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5779ec33-15fd-41d7-85fd-49897bfa3d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MLflow experiment\n",
    "mlflow.set_experiment('GPT2Tutorial')\n",
    "\n",
    "# Create your register your model with MLflow\n",
    "with mlflow.start_run() as run:\n",
    "    model_info = mlflow.transformers.log_model(\n",
    "        model,\n",
    "        'gpt2',\n",
    "        model_config = model_config,\n",
    "        signature = signature,\n",
    "        registered_model_name = 'gpt2'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0b8662-015f-42ac-bdca-93a50cefc939",
   "metadata": {},
   "source": [
    "## Make Predictions with Your Deployed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1770c7f9-ec65-461a-8299-071abd0556fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e35ea0c-79e2-4493-b5e2-42b085c93820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User and default API key, if the default environment file is used (NOT RECOMMENDED FOR ANYTHING OTHER THAN TESTING PURPOSES)\n",
    "user = 'odsp'\n",
    "key = 'odsp-odsp'\n",
    "\n",
    "# Make a prediction using the deployed model\n",
    "\n",
    "# Note that the model is being deployed as an MLflow pyfunc object with a version number\n",
    "# Make sure that you're careful to point to the correct model version (in the example, it's 1) when making your request\n",
    "with requests.Session() as sess:\n",
    "    resp = sess.post('http://model-server:4488/models/predict/gpt2/pyfunc/1', json = {'data' : ['Tell me about yourself.']}, auth = ('odsp', 'odsp-odsp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5348fa3f-ddd4-406f-b99d-c3eb632cc1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the model's predictions\n",
    "print(resp.json()['prediction'][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
