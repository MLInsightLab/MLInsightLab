version: '3.7'

services:

  spark-master:
    image: bitnami/spark@sha256:a5e3feb9397675e9153bdfc748ff3118f333b5b2addf1e7ab19a82128438d4ca
    container_name: spark-master
    ports:
      - "8080:8080"  # Spark UI
      - "7077:7077"  # Spark Master
    environment:
      - SPARK_MODE=master

  spark-worker:
    image: bitnami/spark@sha256:a5e3feb9397675e9153bdfc748ff3118f333b5b2addf1e7ab19a82128438d4ca
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    deploy:
      replicas: 4
  
  jupyter:
    restart: always
    build: ./jupyterhub
    image: jupyter
    container_name: jupyter
    ports:
      - "8000:8000"
      - "8081:8081"
    volumes:
      - notebooks:/home
      - jh_db:/jh_db
      - type: bind
        source: /var/run/docker.sock
        target: /var/run/docker.sock
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:2244

  mlflow:
    restart: always
    build: ./mlflow
    image: mlflow
    container_name: mlflow
    ports:
      - "2244:2244"
    volumes:
      - mlflow_backend_storage:/backend_uri
      - mlflow_artifact_storage:/artifact_store
    environment:
      - MLFLOW_BACKEND_STORE_URI=sqlite:////backend_uri/backend_store.sqlite
      - MLFLOW_TRACKING_URI=http://mlflow:2244
      - MLFLOW_TRACKING_ARTIFACT_STORE=file:///artifact_store
    entrypoint: /bin/sh -c "mlflow server --artifacts-destination file:///artifact_store --host 0.0.0.0 --port 2244"

volumes:
    mlflow_backend_storage:
    mlflow_artifact_storage:
    notebooks:
    jh_db: